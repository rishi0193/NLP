{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syFaTlmbj_si",
        "outputId": "be3096c8-ae66-4fd9-e4f3-f3684282d46c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-03 09:16:14--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-09-03 09:16:14--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-09-03 09:16:15--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2024-09-03 09:18:54 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "# Download GloVe embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Preprocess the Data\n"
      ],
      "metadata": {
        "id": "jtgWg100ZYu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Download NLTK tokenizer models\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('IMDB Dataset.csv')\n",
        "\n",
        "# Encode the labels (positive -> 1, negative -> 0)\n",
        "label_encoder = LabelEncoder()\n",
        "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
        "\n",
        "# Train-test split\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "train_data['tokens'] = train_data['review'].apply(word_tokenize)\n",
        "test_data['tokens'] = test_data['review'].apply(word_tokenize)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file):\n",
        "    embeddings = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, \"Loading GloVe\"):\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_file = 'glove.6B.100d.txt'  # Make sure you have this file downloaded\n",
        "glove_embeddings = load_glove_embeddings(glove_file)\n",
        "embedding_dim = 100\n",
        "\n",
        "# Prepare vocabulary and word embeddings matrix\n",
        "vocab = set([word for tokens in train_data['tokens'] for word in tokens])\n",
        "word_to_idx = {word: idx + 1 for idx, word in enumerate(vocab)}\n",
        "word_to_idx[\"<PAD>\"] = 0  # Padding index\n",
        "\n",
        "# Create an embedding matrix\n",
        "embedding_matrix = np.zeros((len(word_to_idx) + 1, embedding_dim))\n",
        "for word, idx in word_to_idx.items():\n",
        "    embedding_vector = glove_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "# Convert tokens to indices\n",
        "def tokens_to_indices(tokens, word_to_idx):\n",
        "    return [word_to_idx.get(token, 0) for token in tokens]\n",
        "\n",
        "train_data['indices'] = train_data['tokens'].apply(lambda x: tokens_to_indices(x, word_to_idx))\n",
        "test_data['indices'] = test_data['tokens'].apply(lambda x: tokens_to_indices(x, word_to_idx))\n",
        "\n",
        "# Padding sequences\n",
        "def pad_sequences(sequences, maxlen):\n",
        "    return [seq[:maxlen] + [0]*(maxlen - len(seq)) if len(seq) < maxlen else seq[:maxlen] for seq in sequences]\n",
        "\n",
        "max_len = 200  # Define a maximum length for padding\n",
        "train_data['padded'] = pad_sequences(train_data['indices'], max_len)\n",
        "test_data['padded'] = pad_sequences(test_data['indices'], max_len)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(train_data['padded'].tolist())\n",
        "y_train = torch.tensor(train_data['sentiment'].tolist(), dtype=torch.float32)\n",
        "X_test = torch.tensor(test_data['padded'].tolist())\n",
        "y_test = torch.tensor(test_data['sentiment'].tolist(), dtype=torch.float32)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5nManUPkTgw",
        "outputId": "f903eb2e-9cc5-42bc-b5f7-9b8ae4354132"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Loading GloVe: 400000it [00:15, 25501.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Vanilla RNN with GloVe Embeddings"
      ],
      "metadata": {
        "id": "fzcuGX0KZheB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, vocab_size, embedding_matrix):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False  # Freeze embedding layer\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, hidden = self.rnn(x)\n",
        "        hidden = hidden[-1]\n",
        "        return self.fc(hidden)\n",
        "\n",
        "# Model instantiation\n",
        "hidden_dim = 256\n",
        "output_dim = 1\n",
        "vocab_size = len(word_to_idx) + 1\n",
        "rnn_model = RNNModel(embedding_dim, hidden_dim, output_dim, vocab_size, embedding_matrix)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(rnn_model.parameters())\n"
      ],
      "metadata": {
        "id": "k4-zBpy0lV72"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM with GloVe Embeddings\n"
      ],
      "metadata": {
        "id": "LOOWnfv_ZwUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, vocab_size, embedding_matrix):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False  # Freeze embedding layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, (hidden, _) = self.lstm(x)\n",
        "        hidden = hidden[-1]\n",
        "        return self.fc(hidden)\n",
        "\n",
        "# Model instantiation\n",
        "lstm_model = LSTMModel(embedding_dim, hidden_dim, output_dim, vocab_size, embedding_matrix)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion_l = nn.BCEWithLogitsLoss()\n",
        "optimizer_l = optim.Adam(lstm_model.parameters())\n"
      ],
      "metadata": {
        "id": "tYGRD-UDM1Wy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Models\n"
      ],
      "metadata": {
        "id": "pwPxiRCmZ39Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, optimizer, criterion, n_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output.squeeze(), y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
        "\n",
        "# Train Vanilla RNN Model\n",
        "train_model(rnn_model, train_loader, optimizer, criterion)\n",
        "\n",
        "# Train LSTM Model\n",
        "train_model(lstm_model, train_loader, optimizer_l, criterion_l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0BqItJzM_wF",
        "outputId": "823efe56-4b0a-4edf-a1ef-13b41c62a0e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6983772928237915\n",
            "Epoch 2, Loss: 0.6974422760009765\n",
            "Epoch 3, Loss: 0.695209515953064\n",
            "Epoch 4, Loss: 0.6945141072273254\n",
            "Epoch 5, Loss: 0.6937107044219971\n",
            "Epoch 1, Loss: 0.6904668976783752\n",
            "Epoch 2, Loss: 0.6908426870346069\n",
            "Epoch 3, Loss: 0.6717964559555054\n",
            "Epoch 4, Loss: 0.5713755627155304\n",
            "Epoch 5, Loss: 0.3941732023000717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "MOgTmL9DZ8v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            output = model(X_batch)\n",
        "            predictions = torch.round(torch.sigmoid(output.squeeze()))\n",
        "            y_true.extend(y_batch.tolist())\n",
        "            y_pred.extend(predictions.tolist())\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return accuracy, f1\n",
        "\n",
        "accuracy, f1 = evaluate_model(rnn_model, test_loader)\n",
        "print(f'Vanilla RNN with GloVe: Accuracy: {accuracy}, F1: {f1}')\n",
        "\n",
        "accuracy, f1 = evaluate_model(lstm_model, test_loader)\n",
        "print(f'LSTM with GloVe: Accuracy: {accuracy}, F1: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIaSgs-PNGHo",
        "outputId": "e84dcb80-b74d-4103-8a2f-9f6356ba5ced"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla RNN with GloVe: Accuracy: 0.5247, F1: 0.4509645373686034\n",
            "LSTM with GloVe: Accuracy: 0.8274, F1: 0.8339746056175452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r055rktD7yUV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}