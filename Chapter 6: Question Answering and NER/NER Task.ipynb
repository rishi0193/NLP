{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NER Task\nRishi Gandhi J022","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-15T04:54:22.833022Z","iopub.execute_input":"2024-09-15T04:54:22.833498Z","iopub.status.idle":"2024-09-15T04:54:23.320336Z","shell.execute_reply.started":"2024-09-15T04:54:22.833451Z","shell.execute_reply":"2024-09-15T04:54:23.319074Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/pii-detection-removal-from-educational-data/sample_submission.csv\n/kaggle/input/pii-detection-removal-from-educational-data/train.json\n/kaggle/input/pii-detection-removal-from-educational-data/test.json\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Load data\ntrain_df = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/train.json')\ntest_df = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/test.json')\n\n# Display the first few rows and data types\nprint(\"Train DataFrame:\")\nprint(train_df.head())\nprint(train_df.info())\n\nprint(\"\\nTest DataFrame:\")\nprint(test_df.head())\nprint(test_df.info())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T05:07:32.825285Z","iopub.execute_input":"2024-09-15T05:07:32.825868Z","iopub.status.idle":"2024-09-15T05:07:34.788628Z","shell.execute_reply.started":"2024-09-15T05:07:32.825816Z","shell.execute_reply":"2024-09-15T05:07:34.787343Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Train DataFrame:\n   document                                          full_text  \\\n0         7  Design Thinking for innovation reflexion-Avril...   \n1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n4        56  Assignment:  Visualization Reflection  Submitt...   \n\n                                              tokens  \\\n0  [Design, Thinking, for, innovation, reflexion,...   \n1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n4  [Assignment, :,   , Visualization,  , Reflecti...   \n\n                                 trailing_whitespace  \\\n0  [True, True, True, True, False, False, True, F...   \n1  [True, False, False, True, True, False, False,...   \n2  [True, False, False, True, True, False, False,...   \n3  [True, True, True, False, False, True, False, ...   \n4  [False, False, False, False, False, False, Fal...   \n\n                                              labels  \n0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6807 entries, 0 to 6806\nData columns (total 5 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   document             6807 non-null   int64 \n 1   full_text            6807 non-null   object\n 2   tokens               6807 non-null   object\n 3   trailing_whitespace  6807 non-null   object\n 4   labels               6807 non-null   object\ndtypes: int64(1), object(4)\nmemory usage: 266.0+ KB\nNone\n\nTest DataFrame:\n   document                                          full_text  \\\n0         7  Design Thinking for innovation reflexion-Avril...   \n1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n4        56  Assignment:  Visualization Reflection  Submitt...   \n\n                                              tokens  \\\n0  [Design, Thinking, for, innovation, reflexion,...   \n1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n4  [Assignment, :,   , Visualization,  , Reflecti...   \n\n                                 trailing_whitespace  \n0  [True, True, True, True, False, False, True, F...  \n1  [True, False, False, True, True, False, False,...  \n2  [True, False, False, True, True, False, False,...  \n3  [True, True, True, False, False, True, False, ...  \n4  [False, False, False, False, False, False, Fal...  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10 entries, 0 to 9\nData columns (total 4 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   document             10 non-null     int64 \n 1   full_text            10 non-null     object\n 2   tokens               10 non-null     object\n 3   trailing_whitespace  10 non-null     object\ndtypes: int64(1), object(3)\nmemory usage: 448.0+ bytes\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if 'labels' column exists and display unique values\nif 'labels' in train_df.columns:\n    print(\"\\nTrain Labels Sample:\")\n    print(train_df['labels'].head())\n    print(\"\\nUnique Train Labels:\")\n    print(train_df['labels'].explode().unique())\n\nif 'labels' in test_df.columns:\n    print(\"\\nTest Labels Sample:\")\n    print(test_df['labels'].head())\n    print(\"\\nUnique Test Labels:\")\n    print(test_df['labels'].explode().unique())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T05:07:42.842960Z","iopub.execute_input":"2024-09-15T05:07:42.843438Z","iopub.status.idle":"2024-09-15T05:07:43.444044Z","shell.execute_reply.started":"2024-09-15T05:07:42.843387Z","shell.execute_reply":"2024-09-15T05:07:43.442254Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nTrain Labels Sample:\n0    [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...\n1    [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...\n2    [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...\n3    [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...\n4    [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...\nName: labels, dtype: object\n\nUnique Train Labels:\n['O' 'B-NAME_STUDENT' 'I-NAME_STUDENT' 'B-URL_PERSONAL' 'B-EMAIL'\n 'B-ID_NUM' 'I-URL_PERSONAL' 'B-USERNAME' 'B-PHONE_NUM' 'I-PHONE_NUM'\n 'B-STREET_ADDRESS' 'I-STREET_ADDRESS' 'I-ID_NUM']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Display sample text data\nprint(\"\\nTrain Text Sample:\")\nprint(train_df['full_text'].head())\n\nprint(\"\\nTest Text Sample:\")\nprint(test_df['full_text'].head())\n\n\n# Check for tokenization specifics\nsample_text = train_df['full_text'].iloc[0]\nprint(\"\\nSample Text for Tokenization:\")\nprint(sample_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T05:08:14.341925Z","iopub.execute_input":"2024-09-15T05:08:14.342420Z","iopub.status.idle":"2024-09-15T05:08:14.352891Z","shell.execute_reply.started":"2024-09-15T05:08:14.342373Z","shell.execute_reply":"2024-09-15T05:08:14.351241Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\nTrain Text Sample:\n0    Design Thinking for innovation reflexion-Avril...\n1    Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...\n2    Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...\n3    Design Thinking for Innovation\\n\\nSindy Samaca...\n4    Assignment:  Visualization Reflection  Submitt...\nName: full_text, dtype: object\n\nTest Text Sample:\n0    Design Thinking for innovation reflexion-Avril...\n1    Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...\n2    Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...\n3    Design Thinking for Innovation\\n\\nSindy Samaca...\n4    Assignment:  Visualization Reflection  Submitt...\nName: full_text, dtype: object\n\nSample Text for Tokenization:\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n\nChallenge & selection\n\nThe tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\n\nWhat exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf Annex1\n\nThis tool has many advantages:\n\n•  It is accessible to all and does not require significant material investment and can be done  quickly\n\n•  It is scalable\n\n•  It allows categorization and linking of information\n\n•  It can be applied to any type of situation: notetaking, problem solving, analysis, creation of  new ideas\n\n•  It is suitable for all people and is easy to learn\n\n•  It is fun and encourages exchanges\n\n•  It makes visible the dimension of projects, opportunities, interconnections\n\n•  It synthesizes\n\n•  It makes the project understandable\n\n•  It allows you to explore ideas\n\nThe creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.\n\nThis tool enables creativity and logic to be mobilized, it is a map of the thoughts.\n\nCreativity is enhanced because participants feel comfortable with the method.\n\nApplication & Insight\n\nI start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.\n\nThrough a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.\n\nThe use of the “why” is very interesting to understand the origin. By this way, the interviewed person  frees itself from paradigms and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.\n\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n\nAfter modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and interconnections. This second workshop also lasts  two hours and allows the mind map to evolve. Once familiarized with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have learned to work  together and want to make visible the untold ideas.\n\nI now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.\n\nApproach\n\nWhat I find amazing with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.\n\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n\nAnnex 1: Mind Map Shared facilities project\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create dummy labels for test data if necessary\nif 'labels' not in test_df.columns:\n    # Assume each word in the test text should have a dummy label\n    test_labels = [[-100] * len(text.split()) for text in test_df['full_text']]\n    test_df['labels'] = test_labels\n\nprint(\"\\nDummy Test Labels Sample:\")\nprint(test_df['labels'].head())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T05:08:24.885033Z","iopub.execute_input":"2024-09-15T05:08:24.885570Z","iopub.status.idle":"2024-09-15T05:08:24.900025Z","shell.execute_reply.started":"2024-09-15T05:08:24.885512Z","shell.execute_reply":"2024-09-15T05:08:24.898198Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\nDummy Test Labels Sample:\n0    [-100, -100, -100, -100, -100, -100, -100, -10...\n1    [-100, -100, -100, -100, -100, -100, -100, -10...\n2    [-100, -100, -100, -100, -100, -100, -100, -10...\n3    [-100, -100, -100, -100, -100, -100, -100, -10...\n4    [-100, -100, -100, -100, -100, -100, -100, -10...\nName: labels, dtype: object\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Loading:\n\nLoad training and test data from JSON files.\n\n# Label Mapping:\n\nCreate a mapping from label names to numerical IDs and vice versa.\n\n# Data Conversion:\n\nConvert text labels to numerical IDs and prepare dummy labels for the test data if they don't exist.\n\n# Tokenization:\n\nTokenize text and align labels with tokens.\n\n# Training Arguments:\n\nDefine arguments for training such as the number of epochs, batch size, and logging settings.\n\n# Training:\n\nInitialize the Trainer with the model, arguments, and datasets, then train the model.\n\n# Evaluation:\n\nEvaluate the model's performance and print results.\n\n# Inference:\n\nSave the model, load it for inference, and use a pipeline to make predictions on sample text.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nfrom transformers import DebertaTokenizerFast, DebertaForTokenClassification, Trainer, TrainingArguments\nfrom transformers import pipeline\n\n# Define label mapping\nlabel_list = ['O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-URL_PERSONAL', 'B-EMAIL', \n              'B-ID_NUM', 'I-URL_PERSONAL', 'B-USERNAME', 'B-PHONE_NUM', 'I-PHONE_NUM', \n              'B-STREET_ADDRESS', 'I-STREET_ADDRESS', 'I-ID_NUM']\n\nlabel_to_id = {label: i for i, label in enumerate(label_list)}\nid_to_label = {i: label for i, label in enumerate(label_list)}\n\n# Load tokenizer and model\nmodel_name = \"microsoft/deberta-base\"\ntokenizer = DebertaTokenizerFast.from_pretrained(model_name)\nmodel = DebertaForTokenClassification.from_pretrained(model_name, num_labels=len(label_to_id))\n\n# Load data\ntrain_df = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/train.json')\ntest_df = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/test.json')\n\n# Convert labels to IDs\ndef convert_labels_to_ids(labels):\n    return [label_to_id.get(label, -1) for label in labels]\n\ntrain_df['labels'] = train_df['labels'].apply(convert_labels_to_ids)\n\n# Handle test data (create dummy labels if necessary)\nif 'labels' not in test_df.columns:\n    test_labels = [[-100] * len(text.split()) for text in test_df['full_text']]\n    test_df['labels'] = test_labels\n\n# Convert DataFrame to HuggingFace Dataset\ntrain_dataset = Dataset.from_pandas(train_df[['full_text', 'labels']])\ntest_dataset = Dataset.from_pandas(test_df[['full_text', 'labels']])\n\n# Define a function to tokenize and align labels\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples['full_text'], truncation=True, padding=\"max_length\", max_length=128, is_split_into_words=False)\n    \n    labels = []\n    for i, label in enumerate(examples['labels']):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        aligned_labels = [-100] * len(tokenized_inputs.input_ids[i])\n        for word_id in word_ids:\n            if word_id is not None and word_id < len(label):\n                aligned_labels[word_id] = label[word_id]\n        labels.append(aligned_labels)\n    \n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\n# Tokenize and align labels\ntrain_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\ntest_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n\n# Define TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=3,              # number of training epochs\n    per_device_train_batch_size=8,   # batch size for training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    evaluation_strategy=\"epoch\",     # evaluate model after each epoch\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,                         # the instantiated Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=test_dataset,           # evaluation dataset\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate the model\nresults = trainer.evaluate()\n\nprint(\"\\nEvaluation Results:\")\nprint(results)\n\n# Save the model\nmodel.save_pretrained('./model')\ntokenizer.save_pretrained('./model')\n\n# Load the model for inference\nmodel = DebertaForTokenClassification.from_pretrained('./model')\ntokenizer = DebertaTokenizerFast.from_pretrained('./model')\n\n# Create a pipeline for NER\nnlp_ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n\n# Example prediction\nsample_text = \"Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\"\npredictions = nlp_ner(sample_text)\n\nprint(\"\\nSample Predictions:\")\nprint(predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T05:21:10.015444Z","iopub.execute_input":"2024-09-15T05:21:10.015731Z","iopub.status.idle":"2024-09-15T05:30:41.876067Z","shell.execute_reply.started":"2024-09-15T05:21:10.015698Z","shell.execute_reply":"2024-09-15T05:30:41.875057Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03293d7ada6d4177b0a45e5397f32039"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99ff56ab2f2e4689960f2f73c6d4635c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55e02911324644a4b2c45dbc90f59844"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73da72521a984dfa834cfe387dfc3e6f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/559M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a75af68a203e49bb94d5009f3533b9d4"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6807 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51ac24651163443f9c68306b2add93b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda7f819fb15499c8743415563feced2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  \n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240915_052209-o06ba60l</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rishigandhi6789-svkm-s-narsee-monjee-institute-of-manage/huggingface/runs/o06ba60l' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/rishigandhi6789-svkm-s-narsee-monjee-institute-of-manage/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rishigandhi6789-svkm-s-narsee-monjee-institute-of-manage/huggingface' target=\"_blank\">https://wandb.ai/rishigandhi6789-svkm-s-narsee-monjee-institute-of-manage/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rishigandhi6789-svkm-s-narsee-monjee-institute-of-manage/huggingface/runs/o06ba60l' target=\"_blank\">https://wandb.ai/rishigandhi6789-svkm-s-narsee-monjee-institute-of-manage/huggingface/runs/o06ba60l</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1278' max='1278' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1278/1278 08:11, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.006100</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.002800</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.003500</td>\n      <td>nan</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nEvaluation Results:\n{'eval_loss': nan, 'eval_runtime': 0.127, 'eval_samples_per_second': 78.753, 'eval_steps_per_second': 7.875, 'epoch': 3.0}\n","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"\nSample Predictions:\n[{'entity_group': 'LABEL_0', 'score': 0.9483422, 'word': 'Design Thinking for innovation reflexion-Avril', 'start': 0, 'end': 46}, {'entity_group': 'LABEL_2', 'score': 0.4250323, 'word': ' 2021', 'start': 46, 'end': 51}, {'entity_group': 'LABEL_0', 'score': 0.94255066, 'word': '-Nathalie Sylla', 'start': 51, 'end': 66}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Evaluation Results:\n\neval_loss: nan\n\neval_runtime: 0.127 seconds\n\neval_samples_per_second: 78.753\n\neval_steps_per_second: 7.875\n\nepoch: 3.0\n\nSample Predictions:\n\nEntity: LABEL_0, Score: 0.9483422, Word: Design Thinking for innovation reflexion-Avril, Start: 0, End: 46\n\nEntity: LABEL_2, Score: 0.4250323, Word: 2021, Start: 46, End: 51\n\nEntity: LABEL_0, Score: 0.94255066, Word: -Nathalie Sylla, Start: 51, End: 66\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}